{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e330445",
   "metadata": {},
   "source": [
    "# LangChain Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f98a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AIMessage,  HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c6c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75901e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_file = open(\"../../api_key.txt\")\n",
    "api_key = api_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "993c31b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f57ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c54439",
   "metadata": {},
   "source": [
    "## LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9455d81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nMars has the largest dust storms in the Solar System, which can last for months and cover the entire planet.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Here is a fact about Mars:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfd0bc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mars has the largest dust storms in the Solar System, which can last for months and cover the entire planet.\n"
     ]
    }
   ],
   "source": [
    "planet = 'Mars'\n",
    "print(llm(f\"Here is a fact about {planet}:\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b3d916",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3a0b1f",
   "metadata": {},
   "source": [
    "#### No Input Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "454a8a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_input_prompt = PromptTemplate(input_variables=[], \n",
    "                                 template=\"Tell me a fact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69d4b88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a fact'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_input_prompt.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91b1a4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe average human body contains enough sulfur to kill all the fleas on an average dog.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(no_input_prompt.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c81614f",
   "metadata": {},
   "source": [
    "#### Single Input Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b9916ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_input_prompt = PromptTemplate(input_variables=[\"topic\"], \n",
    "                                     template='Tell me a fact about {topic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c1eb203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe Pacific Ocean is the largest ocean in the world, covering 30% of the Earthâ€™s surface.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(single_input_prompt.format(topic='the ocean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5a844d",
   "metadata": {},
   "source": [
    "#### Multiple Input Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00fa121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_input_prompt = PromptTemplate(input_variables=[\"topic\", \"level\"],\n",
    "                                       template='Tell me a fact about {topic} for a {level} student')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fe55c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe ocean is home to more than 230,000 known species of plants and animals, but is estimated to contain as many as two million species that are still undiscovered.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(multiple_input_prompt.format(topic='the ocean', level='PhD level'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023504f8",
   "metadata": {},
   "source": [
    "## Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f8aec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.prompts import SystemMessagePromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8351a895",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"You are an AI recipe assistant that specializes in {dietry_preference} dishes that can be prepared in {cooking_time}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf8bea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcee77ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cooking_time', 'dietry_preference']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43653e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"{recipe_request}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59f658cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49e0b5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recipe_request']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "131f221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message_prompt,\n",
    "    human_message_prompt\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4938fbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cooking_time', 'dietry_preference', 'recipe_request']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab1557ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.format_prompt(cooking_time = '15 minutes',\n",
    "                          dietry_preference = 'Vegan',\n",
    "                          recipe_request = 'quick snack').to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d470c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7c4d619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One quick and easy vegan snack idea is a Hummus and Veggie Wrap. Here's how you can make it in just 15 minutes:\n",
      "\n",
      "Ingredients:\n",
      "- 1 large whole wheat tortilla\n",
      "- 1/4 cup hummus\n",
      "- 1/4 cup sliced cucumber\n",
      "- 1/4 cup sliced bell peppers\n",
      "- 1/4 cup shredded carrots\n",
      "- Handful of baby spinach or lettuce leaves\n",
      "\n",
      "Instructions:\n",
      "1. Lay the tortilla flat on a clean surface or plate.\n",
      "2. Spread the hummus evenly over the tortilla.\n",
      "3. Place the sliced cucumber, bell peppers, shredded carrots, and spinach leaves on top of the hummus.\n",
      "4. Roll up the tortilla tightly, tucking in the sides as you go.\n",
      "5. Slice the wrap in half or into bite-sized pieces.\n",
      "6. Serve and enjoy your delicious and nutritious hummus and veggie wrap!\n",
      "\n",
      "Feel free to customize this recipe by adding other veggies or seasonings that you enjoy.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fccf59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
